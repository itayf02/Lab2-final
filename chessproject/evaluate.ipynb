{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stockfish\n",
      "  Downloading stockfish-3.28.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading stockfish-3.28.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: stockfish\n",
      "Successfully installed stockfish-3.28.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockfish import Stockfish\n",
    "sf = Stockfish(path=\"stockfish\\stockfish-windows-x86-64-avx2.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch.utils.data import Dataset\n",
    "import chess\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATConv,GINConv,TransformerConv,global_add_pool, global_mean_pool,global_max_pool,max_pool_neighbor_x\n",
    "from torch_geometric.loader import DataListLoader,DataLoader\n",
    "from sklearn.metrics import recall_score\n",
    "# from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from info_nce import InfoNCE, info_nce\n",
    "from pytorch_metric_learning import losses\n",
    "import warnings\n",
    "import chess.pgn\n",
    "import chess\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pgn_file2(pgn_file_path,_len):\n",
    "    pgn = open(pgn_file_path)\n",
    "\n",
    "    posdict = {\n",
    "        \"fen\": [],\n",
    "        \"capture\": [],\n",
    "        \"first_five\": [],\n",
    "        \"last_five\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "\n",
    "    for i in tqdm(range(_len)):  # Assuming 33255 games to process\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        board = chess.Board()\n",
    "\n",
    "        result_tag = game.headers[\"Result\"]\n",
    "        if result_tag == \"1/2-1/2\":\n",
    "            continue  # Skip draws\n",
    "\n",
    "        white_wins = (result_tag == \"1-0\")\n",
    "        moves = list(game.mainline_moves())\n",
    "\n",
    "        # Filter positions: not a capture and not within the first five moves\n",
    "        eligible_positions = []\n",
    "\n",
    "        for idx, move in enumerate(moves):\n",
    "\n",
    "            capture = board.is_capture(move)\n",
    "            board.push(move)\n",
    "            first_five = idx < 9\n",
    "\n",
    "            if not capture and not first_five:\n",
    "                eligible_positions.append((board.fen(), idx, len(moves)))\n",
    "\n",
    "        # If there are eligible positions, select a random one\n",
    "        if eligible_positions:\n",
    "            fen, idx, total_moves = random.choice(eligible_positions)\n",
    "            last_five = idx > (total_moves - 5)\n",
    "\n",
    "            posdict[\"fen\"].append(fen)\n",
    "            posdict[\"capture\"].append(False)  # By definition, not a capture\n",
    "            posdict[\"first_five\"].append(False)  # By definition, not in the first five\n",
    "            posdict[\"last_five\"].append(last_five)\n",
    "            posdict[\"label\"].append(white_wins)\n",
    "\n",
    "    return posdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28747 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28747/28747 [03:11<00:00, 150.23it/s]\n",
      "100%|██████████| 28641/28641 [03:12<00:00, 148.82it/s]\n",
      "100%|██████████| 24382/24382 [02:37<00:00, 154.37it/s]\n",
      "100%|██████████| 15540/15540 [01:35<00:00, 162.51it/s]\n",
      "100%|██████████| 13317/13317 [01:15<00:00, 177.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40125 entries, 0 to 40124\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   fen         40125 non-null  object\n",
      " 1   capture     40125 non-null  bool  \n",
      " 2   first_five  40125 non-null  bool  \n",
      " 3   last_five   40125 non-null  bool  \n",
      " 4   label       40125 non-null  bool  \n",
      "dtypes: bool(4), object(1)\n",
      "memory usage: 470.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dict_lst = []\n",
    "test_pgn_path = 'test_data/2024-02.bare.[28747].pgn'\n",
    "dict_lst.append(process_pgn_file2(test_pgn_path,28747))\n",
    "test_pgn_path = 'test_data/2024-03.bare.[28641].pgn'\n",
    "dict_lst.append(process_pgn_file2(test_pgn_path,28641))\n",
    "test_pgn_path = 'test_data/2024-04.bare.[24382].pgn'\n",
    "dict_lst.append(process_pgn_file2(test_pgn_path,24382))\n",
    "test_pgn_path = 'test_data/2024-05.bare.[15540].pgn'\n",
    "dict_lst.append(process_pgn_file2(test_pgn_path,15540))\n",
    "test_pgn_path = 'test_data/2024-06.bare.[13317].pgn'\n",
    "dict_lst.append(process_pgn_file2(test_pgn_path,13317))\n",
    "posdict = {\n",
    "        \"fen\": [],\n",
    "        \"capture\": [],\n",
    "        \"first_five\": [],\n",
    "        \"last_five\": [],\n",
    "        \"label\": []\n",
    "    }\n",
    "for dct in dict_lst:\n",
    "    for key in posdict.keys():\n",
    "        posdict[key] = posdict[key]+dct[key]\n",
    "\n",
    "test = pd.DataFrame(posdict)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def chess_position_to_graph(board):\n",
    "    G = nx.DiGraph()  # Directed graph\n",
    "\n",
    "    # Ensure all squares are included as nodes\n",
    "    for square in chess.SQUARES:\n",
    "        G.add_node(chess.square_name(square))\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            # Get all squares attacked by the piece on the current square\n",
    "            attacked_squares = board.attacks(square)\n",
    "            for target_square in attacked_squares:\n",
    "                # Add a directed edge from the attacking square to the attacked square\n",
    "                from_square_name = chess.square_name(square)\n",
    "                to_square_name = chess.square_name(target_square)\n",
    "                G.add_edge(from_square_name, to_square_name)\n",
    "    # Get the legal moves for the current player\n",
    "    current_moves = list(board.legal_moves)\n",
    "\n",
    "\n",
    "    # Add edges for the current player's moves\n",
    "    for move in current_moves:\n",
    "        from_square_name = chess.square_name(move.from_square)\n",
    "        to_square_name = chess.square_name(move.to_square)\n",
    "        G.add_edge(from_square_name, to_square_name)\n",
    "\n",
    "    # Temporarily switch turns to the opponent\n",
    "    board.push(chess.Move.null())\n",
    "\n",
    "    # Get the legal moves for the opponent\n",
    "    opponent_moves = list(board.legal_moves)\n",
    "\n",
    "\n",
    "    # Add edges for the opponent's moves\n",
    "    for move in opponent_moves:\n",
    "        from_square_name = chess.square_name(move.from_square)\n",
    "        to_square_name = chess.square_name(move.to_square)\n",
    "        G.add_edge(from_square_name, to_square_name)\n",
    "\n",
    "    G.add_node(\"global\")\n",
    "\n",
    "    # Connect the global node to all squares\n",
    "    for square in chess.SQUARES:\n",
    "        square_name = chess.square_name(square)\n",
    "        G.add_edge(\"global\", square_name)  # Edge from global node to square\n",
    "        G.add_edge(square_name, \"global\")  # Edge from square to global node\n",
    "\n",
    "    # Restore the board to the original state\n",
    "    # G = G.to_undirected()\n",
    "    board.pop()\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_to_coordinates(square):\n",
    "    \"\"\"Convert a square index to board coordinates.\"\"\"\n",
    "    row = square // 8 + 1\n",
    "    col = square % 8 + 1\n",
    "    return [col, row]\n",
    "\n",
    "def distance_to_center(square):\n",
    "    \"\"\"\n",
    "    Calculate the distance of a square to the center of the board.\n",
    "    \"\"\"\n",
    "    row, col = divmod(square, 8)\n",
    "    center_row, center_col = 3.5, 3.5  # Center of the board is at (3.5, 3.5)\n",
    "    return np.sqrt((row - center_row) ** 2 + (col - center_col) ** 2) / 4.95  # Normalize distance\n",
    "\n",
    "\n",
    "def piece_to_one_hot(piece):\n",
    "    \"\"\"Convert a chess piece to a one-hot encoding including color.\"\"\"\n",
    "    pieces = {\n",
    "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "    }\n",
    "    one_hot = [0] * 12\n",
    "    if piece:\n",
    "        one_hot[pieces[piece.symbol()]] = 1\n",
    "    return one_hot\n",
    "def piece_to_value(piece):\n",
    "    pieces = {\n",
    "        'P': 100, 'N': 320, 'B': 330, 'R': 500, 'Q': 900, 'K': 20000,\n",
    "        'p': -100, 'n': -320, 'b': -330, 'r': -500, 'q': -900, 'k': -20000\n",
    "    }\n",
    "    if piece:\n",
    "        return [pieces[piece.symbol()]]\n",
    "    return [0]\n",
    "\n",
    "def create_node_embeddings(board:chess.Board):\n",
    "    embeddings = []\n",
    "    for square in chess.SQUARES:\n",
    "        coordinates = square_to_coordinates(square)\n",
    "        piece = board.piece_at(square)\n",
    "        piece_one_hot = piece_to_one_hot(piece)\n",
    "        piece_value = piece_to_value(piece)\n",
    "        center_distance = distance_to_center(square)\n",
    "        is_attacked_white = int(board.is_attacked_by(True, square))\n",
    "        is_attacked_black = int(board.is_attacked_by(False, square))\n",
    "        is_check = int(board.is_check())\n",
    "        embeddings.append(coordinates+piece_one_hot+piece_value+[center_distance]+[-1**(1-int(board.turn)),is_attacked_white,is_attacked_black,is_check])\n",
    "    embeddings.append(torch.zeros(20))\n",
    "    return torch.tensor(embeddings, dtype=torch.float)\n",
    "\n",
    "def chess_position_to_torch_geometric_data(board):\n",
    "    # Create the graph using the previous function\n",
    "    G = chess_position_to_graph(board)\n",
    "\n",
    "    # Convert the NetworkX graph to edge_index format for torch_geometric\n",
    "    edge_index = pyg_utils.from_networkx(G).edge_index\n",
    "\n",
    "    # Create node embeddings\n",
    "    node_embeddings = create_node_embeddings(board)\n",
    "\n",
    "    # Create the torch_geometric data object\n",
    "    data = Data(x=node_embeddings, edge_index=edge_index)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39965 entries, 0 to 39964\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   fen     39965 non-null  object\n",
      " 1   0       39965 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 351.4+ KB\n",
      "None\n",
      "39965\n",
      "40125\n"
     ]
    }
   ],
   "source": [
    "class ChessPositionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by filtering the DataFrame to exclude\n",
    "        capture moves and positions marked as first_five.\n",
    "\n",
    "        :param df: DataFrame containing chess positions with columns:\n",
    "                   'fen', 'capture', 'first_five', 'last_five', 'label'\n",
    "        \"\"\"\n",
    "        # Filter the DataFrame to exclude capture moves and first five moves\n",
    "        self.df = df[(~df['capture']) & (~df['first_five'])].reset_index(drop=True)\n",
    "        self.df = self.df.groupby('fen').apply(self.determine_majority_label).reset_index().reset_index(drop=True)\n",
    "        print(self.df.info())\n",
    "        self.df.columns = ['fen', 'label']\n",
    "\n",
    "\n",
    "    def determine_majority_label(self,group):\n",
    "    # Determine the majority label (mode); if tied, select the first mode\n",
    "        return group['label'].mode()[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def get_graph(self, fen):\n",
    "        \"\"\"\n",
    "        Converts a FEN string into a graph representation using the provided\n",
    "        function chess_position_to_torch_geometric_data.\n",
    "\n",
    "        :param fen: FEN string representing the chess board state\n",
    "        :return: Graph representation of the position\n",
    "        \"\"\"\n",
    "        # Create a chess board from the FEN string\n",
    "        board = chess.Board(fen=fen)\n",
    "\n",
    "        # Generate the graph data using the chess_position_to_torch_geometric_data function\n",
    "        graph_data = chess_position_to_torch_geometric_data(board)\n",
    "\n",
    "        return graph_data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sample from the dataset.\n",
    "\n",
    "        :param idx: Index of the sample\n",
    "        :return: Tuple (graph_data, label) where graph_data is the graph representation\n",
    "                 of the position and label is its target label\n",
    "        \"\"\"\n",
    "        # Get the FEN string and the label\n",
    "        fen = self.df.loc[idx, 'fen']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "\n",
    "\n",
    "        # Generate the graph representation of the position\n",
    "        graph_data = self.get_graph(fen)\n",
    "\n",
    "        # Convert label to a tensor\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        return graph_data, label_tensor\n",
    "\n",
    "# Example usage:\n",
    "fen_dataset = test[[\"fen\",\"label\"]]\n",
    "dataset = ChessPositionDataset(test)\n",
    "print(len(dataset))\n",
    "print(len(fen_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fen_dataframe_with_stockfish(fen_df, stockfish_path):\n",
    "    labeled_data = []\n",
    "\n",
    "    # Initialize Stockfish\n",
    "    with chess.engine.SimpleEngine.popen_uci(stockfish_path) as engine:\n",
    "        for index, row in tqdm(fen_df.iterrows(), total=len(fen_df)):\n",
    "            board = chess.Board(row[\"fen\"])\n",
    "\n",
    "            # Evaluate position with Stockfish\n",
    "            info = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
    "            centipawns = info[\"score\"].white().score(mate_score=100000)  # Arbitrary high for mate\n",
    "\n",
    "            # Determine label based on centipawn evaluation\n",
    "            if centipawns is not None:\n",
    "                if centipawns > 1:  # Winning position\n",
    "                    label = 1\n",
    "                elif centipawns < -1:  # Losing position\n",
    "                    label = 0\n",
    "                else:  # Drawish position\n",
    "                    label = -1\n",
    "            else:\n",
    "                label = 10\n",
    "\n",
    "            labeled_data.append(label)\n",
    "\n",
    "    # Add the labels to the DataFrame\n",
    "    fen_df[\"stock_fish_label\"] = labeled_data\n",
    "    return fen_df\n",
    "\n",
    "stockfish_path=\"stockfish\\stockfish-windows-x86-64-avx2.exe\"\n",
    "# labeled_fen_dataset = label_fen_dataframe_with_stockfish(fen_dataset, stockfish_path)\n",
    "# labeled_fen_dataset.to_csv(\"stockfish_labels.csv\")\n",
    "labeled_fen_dataset = pd.read_csv(\"stockfish_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "seed = 42 # age of SIPL\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "# torch.backends.cuda.matmul.allow_tf32 = False\n",
    "# torch.backends.cudnn.benchmark=False\n",
    "\n",
    "dataloader=DataLoader(dataset, batch_size=16, shuffle=False,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataBatch(x=[1040, 20], edge_index=[2, 3670], batch=[1040], ptr=[17]), tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.])]\n",
      "[DataBatch(x=[1040, 20], edge_index=[2, 3936], batch=[1040], ptr=[17]), tensor([1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1.])]\n",
      "[DataBatch(x=[1040, 20], edge_index=[2, 3666], batch=[1040], ptr=[17]), tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.])]\n",
      "[DataBatch(x=[1040, 20], edge_index=[2, 3717], batch=[1040], ptr=[17]), tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1.])]\n",
      "[DataBatch(x=[1040, 20], edge_index=[2, 3744], batch=[1040], ptr=[17]), tensor([0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    # Process the data here\n",
    "    print(data)  # Example processing; replace with your logic\n",
    "\n",
    "    # Stop after the first 5 batches\n",
    "    if i >= 4:  # 4 because i starts from 0\n",
    "        break\n",
    "# # Test accessing individual items in the dataset\n",
    "# for i in range(5):\n",
    "#     item = dataset[i]\n",
    "#     print(f\"Loaded item {i}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=2,aggr=\"mean\"):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # First GNN layer\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim,aggr=aggr)\n",
    "\n",
    "        # Additional GNN layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(SAGEConv(hidden_dim, hidden_dim,aggr=aggr))\n",
    "        # Fully connected layer to produce graph embedding\n",
    "        self.fc1 = nn.Linear(hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Extract relevant data from the Data object\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply the first GCN layer\n",
    "        x = F.tanh(self.conv1(x, edge_index))\n",
    "\n",
    "        # Apply the remaining GCN layers\n",
    "        for conv in self.convs:\n",
    "            x = F.tanh(conv(x, edge_index))\n",
    "\n",
    "        # Pooling to get the graph-level embedding\n",
    "        x = global_add_pool(x, batch)\n",
    "\n",
    "\n",
    "        # Final fully connected layer\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.2)\n",
    "        x= self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "input_dim = 20  # Example: 2 for location + 12 for one-hot encoding of pieces\n",
    "hidden_dim = 4*256\n",
    "output_dim = 128  # Size of the graph embedding\n",
    "\n",
    "test_model = GNN(input_dim=input_dim, hidden_dim=hidden_dim,num_layers=3,aggr=\"mean\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2498/2498 [05:37<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"trained model\\chess_gnn_model.pth\"\n",
    "test_model.load_state_dict(torch.load(path, map_location=device))  # Load pre-trained weights and map to the correct device\n",
    "test_model.eval()  # Set the model to evaluation mode\n",
    "output_logits = []  # List to store all processed logits\n",
    "output_labels = []  # List to store all corresponding labels\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        graphs, labels = batch  # Unpack graphs and labels from the batch\n",
    "        \n",
    "        # Move data to the correct device\n",
    "        graphs = graphs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass to get the logits\n",
    "        outputs = test_model(graphs).squeeze()  # Squeeze if the output has extra dimensions\n",
    "        \n",
    "        # Process each logit and label\n",
    "        for logit, label in zip(outputs, labels):\n",
    "            # Clip logits based on the given rules\n",
    "            if logit > 0:\n",
    "                output_logits.append(1)\n",
    "            elif logit < 0:\n",
    "                output_logits.append(0)\n",
    "            else:\n",
    "                output_logits.append(-1)\n",
    "            \n",
    "            # Append the corresponding label\n",
    "            output_labels.append(label.item())  # Convert label tensor to a Python scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7156192907375428\n",
      "39957\n"
     ]
    }
   ],
   "source": [
    "avg = 0\n",
    "for i in range(len(output_logits)):\n",
    "    if output_logits[i]==output_labels[i]:\n",
    "        avg+=1\n",
    "print (avg/len(output_logits))\n",
    "print(len(output_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40125\n",
      "470\n",
      "39957\n"
     ]
    }
   ],
   "source": [
    "stock_fish_fen_list = labeled_fen_dataset[\"stock_fish_label\"].to_list()\n",
    "stock_fish__true_labels = labeled_fen_dataset[\"label\"].to_list()\n",
    "print(len(stock_fish_fen_list))\n",
    "avg = 0\n",
    "for i in range(len(stock_fish_fen_list)):\n",
    "    if stock_fish_fen_list[i]==-1:\n",
    "        avg+=1\n",
    "print (avg)\n",
    "print(len(output_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5386790800110118\n"
     ]
    }
   ],
   "source": [
    "avg=0\n",
    "for i in range(len(output_logits)):\n",
    "    if stock_fish_fen_list[i]==output_logits[i]:\n",
    "        avg+=1\n",
    "print(avg/len(output_logits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambaclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
